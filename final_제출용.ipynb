{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a17e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 0. Imports & 기본 설정\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067e3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def add_eda_rule_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) chem_01_range 구간화\n",
    "    df['chem_01_range'] = pd.cut(\n",
    "        df['chem_01'], \n",
    "        bins=[-np.inf, 2.0, 4.0, np.inf], \n",
    "        labels=['Normal_Low', 'Warning_Zone', 'Danger_High']\n",
    "    )\n",
    "\n",
    "    # 2) trace_metal_range 구간화\n",
    "    df['trace_metal_range'] = pd.cut(\n",
    "        df['trace_metal'],\n",
    "        bins=[-np.inf, 90, 130, np.inf],\n",
    "        labels=['Safe', 'Caution', 'Risk']\n",
    "    )\n",
    "\n",
    "    # 3) swelling + chem_01 조합으로 risk_segment 만들기\n",
    "    def check_ambiguous_risk(row):\n",
    "        # S 이면서 chem_01이 2~5 사이 → 주의(1) 의심\n",
    "        if (row['swelling'] == 'S') and (2.0 <= row['chem_01'] < 5.0):\n",
    "            return 'Target_1_Suspect'\n",
    "        # swelling이 Y 이거나 chem_01이 5 이상 → 위험(2)\n",
    "        elif (row['swelling'] == 'Y') or (row['chem_01'] >= 5.0):\n",
    "            return 'High_Risk'\n",
    "        # 나머지는 Normal\n",
    "        else:\n",
    "            return 'Normal'\n",
    "\n",
    "    df['risk_segment'] = df.apply(check_ambiguous_risk, axis=1)\n",
    "\n",
    "    # ⚠️ XGBoost는 object 를 못 먹으니까 숫자로 바꿔야 함\n",
    "    chem_map = {'Normal_Low': 0, 'Warning_Zone': 1, 'Danger_High': 2}\n",
    "    metal_map = {'Safe': 0, 'Caution': 1, 'Risk': 2}\n",
    "    risk_map = {'Normal': 0, 'Target_1_Suspect': 1, 'High_Risk': 2}\n",
    "\n",
    "    df['chem_01_range']     = df['chem_01_range'].map(chem_map).astype(int)\n",
    "    df['trace_metal_range'] = df['trace_metal_range'].map(metal_map).astype(int)\n",
    "    df['risk_segment']      = df['risk_segment'].map(risk_map).astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55d3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 1. 평가 지표 & OOF 유틸 함수\n",
    "\n",
    "# %%\n",
    "def map_macro(y_true, proba):\n",
    "    \"\"\"\n",
    "    macro Average Precision (mAP)\n",
    "    \"\"\"\n",
    "    return average_precision_score(y_true, proba, average=\"macro\")\n",
    "\n",
    "\n",
    "def get_oof_proba(model, X, y, n_splits=N_SPLITS, random_state=RANDOM_STATE, name=\"MODEL\"):\n",
    "    \"\"\"\n",
    "    주어진 모델로 StratifiedKFold OOF 확률 생성\n",
    "    - model: scikit-learn estimator (XGB/LGBM/CatBoost 다 가능)\n",
    "    - X: DataFrame 또는 ndarray\n",
    "    - y: 1D array-like\n",
    "    \"\"\"\n",
    "    X_arr = np.asarray(X)\n",
    "    y_arr = np.asarray(y)\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    n_classes = len(np.unique(y_arr))\n",
    "    oof_proba = np.zeros((len(y_arr), n_classes), dtype=float)\n",
    "    scores = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_arr, y_arr), 1):\n",
    "        X_tr, X_val = X_arr[tr_idx], X_arr[val_idx]\n",
    "        y_tr, y_val = y_arr[tr_idx], y_arr[val_idx]\n",
    "\n",
    "        m = clone(model)\n",
    "        m.fit(X_tr, y_tr)\n",
    "\n",
    "        proba_val = m.predict_proba(X_val)\n",
    "        oof_proba[val_idx] = proba_val\n",
    "\n",
    "        score = map_macro(y_val, proba_val)\n",
    "        print(f\"[{name}] Fold {fold}/{n_splits} mAP = {score:.6f}\")\n",
    "        scores.append(score)\n",
    "\n",
    "    print(f\"[{name}] OOF mean mAP = {np.mean(scores):.6f}\")\n",
    "    return oof_proba, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 2. 피처 엔지니어링 (boosting 통합)\n",
    "\n",
    "# %%\n",
    "def prepare_raw(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - birth_date → age\n",
    "    - gender: M/F → 0/1\n",
    "    나머지 컬럼은 그대로 두고, 이후 함수에서 가공\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # birth_date → age\n",
    "    if \"birth_date\" in df.columns:\n",
    "        df[\"birth_date\"] = pd.to_datetime(df[\"birth_date\"])\n",
    "        df[\"age\"] = 2025 - df[\"birth_date\"].dt.year\n",
    "\n",
    "    # gender: M/F → 0/1\n",
    "    if \"gender\" in df.columns:\n",
    "        df[\"gender\"] = df[\"gender\"].map({\"M\": 0, \"F\": 1})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_boosting_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    거대 피처: health_index, 각종 비율/합/차, 그룹 통계 등\n",
    "    (이전에 쓰던 make_boosting_features 정리 버전)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. health_index & health_per_stage\n",
    "    high_is_healthy = [\"protein_level\", \"blood_cells\"]\n",
    "    low_is_healthy  = [\"enzyme_A\", \"enzyme_B\", \"lipid_index\", \"trace_metal\", \"clot_time\"]\n",
    "\n",
    "    def minmax(s):\n",
    "        s = s.astype(float)\n",
    "        mn, mx = s.min(), s.max()\n",
    "        if mx == mn:\n",
    "            return pd.Series(0.5, index=s.index)\n",
    "        return (s - mn) / (mx - mn + 1e-6)\n",
    "\n",
    "    if all(col in df.columns for col in high_is_healthy + low_is_healthy):\n",
    "        df[\"health_index\"] = (\n",
    "            sum(minmax(df[col]) for col in high_is_healthy)\n",
    "            - sum(minmax(df[col]) for col in low_is_healthy)\n",
    "        )\n",
    "        df[\"health_per_stage\"] = df[\"health_index\"] / (df[\"disease_stage\"] + 1e-6)\n",
    "\n",
    "    # 2. 상호작용 / 비율 / 합·차\n",
    "    df[\"chem01_trace_combo\"]   = df[\"chem_01\"] * df[\"trace_metal\"]\n",
    "    df[\"chem01_chem02_combo\"]  = df[\"chem_01\"] * df[\"chem_02\"]\n",
    "    df[\"chem01_enzymeB_combo\"] = df[\"chem_01\"] * df[\"enzyme_B\"]\n",
    "\n",
    "    df[\"enzyme_ratio\"]       = df[\"enzyme_A\"] / (df[\"enzyme_B\"].replace(0, np.nan) + 1e-6)\n",
    "    df[\"lipid_blood_ratio\"]  = df[\"lipid_index\"] / (df[\"blood_cells\"].replace(0, np.nan) + 1e-6)\n",
    "    df[\"chem02_trace_ratio\"] = df[\"chem_02\"] / (df[\"trace_metal\"].replace(0, np.nan) + 1e-6)\n",
    "\n",
    "    df[\"sum_chem\"]   = df[\"chem_01\"] + df[\"chem_02\"]\n",
    "    df[\"diff_chem\"]  = df[\"chem_01\"] - df[\"chem_02\"]\n",
    "    df[\"sum_enzyme\"] = df[\"enzyme_A\"] + df[\"enzyme_B\"]\n",
    "    df[\"diff_enzyme\"] = df[\"enzyme_A\"] - df[\"enzyme_B\"]\n",
    "\n",
    "    # 3. 시간/나이 정규화\n",
    "    df[\"obs_per_age\"]      = df[\"obs_days\"] / (df[\"age\"] + 1e-6)\n",
    "    df[\"behavior_per_age\"] = df[\"behavior_index\"] / (df[\"age\"] + 1e-6)\n",
    "    df[\"disease_velocity\"] = df[\"disease_stage\"] / (df[\"obs_days\"] + 1e-6)\n",
    "\n",
    "    # 4. 증상 카운트 & 중증도\n",
    "    symptom_cols = [\"fluid_accum\", \"organ_enlarge\", \"vascular_marks\"]\n",
    "    for col in symptom_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace({\"Y\": 1, \"N\": 0})\n",
    "    df[\"symptom_count\"] = df[symptom_cols].sum(axis=1)\n",
    "\n",
    "    # swelling: N/S/Y → 0/1/2\n",
    "    if \"swelling\" in df.columns:\n",
    "        df[\"swelling_ord\"] = df[\"swelling\"].map({\"N\": 0, \"S\": 1, \"Y\": 2})\n",
    "    else:\n",
    "        df[\"swelling_ord\"] = 0\n",
    "\n",
    "    df[\"symptom_severity\"] = df[\"symptom_count\"] + df[\"swelling_ord\"]\n",
    "\n",
    "    # 5. 랭크 기반\n",
    "    for col in [\"chem_01\", \"trace_metal\", \"enzyme_A\", \"enzyme_B\", \"lipid_index\"]:\n",
    "        df[f\"{col}_rank\"] = df[col].rank(method=\"average\") / len(df)\n",
    "\n",
    "    # 6. age_group & 그룹 통계\n",
    "    bins   = [60, 80, 90, 100, 130]\n",
    "    labels = [\"60-79\", \"80-89\", \"90-99\", \"100+\"]\n",
    "\n",
    "    df[\"age_group\"] = pd.cut(\n",
    "        df[\"age\"], bins=bins, labels=labels,\n",
    "        right=False, include_lowest=True\n",
    "    )\n",
    "\n",
    "    group_cols = ['disease_stage', 'gender', 'age_group']\n",
    "    agg_cols = ['enzyme_A', 'enzyme_B', 'protein_level', 'immune_index',\n",
    "                'lipid_index', 'blood_cells']\n",
    "\n",
    "    for group_col in group_cols:\n",
    "        for col in agg_cols:\n",
    "            mean_val = df.groupby(group_col)[col].transform('mean')\n",
    "            std_val  = df.groupby(group_col)[col].transform('std')\n",
    "            max_val  = df.groupby(group_col)[col].transform('max')\n",
    "            min_val  = df.groupby(group_col)[col].transform('min')\n",
    "\n",
    "            prefix = f'{col}_by_{group_col}'\n",
    "            df[f'{prefix}_diff_mean']  = df[col] - mean_val\n",
    "            df[f'{prefix}_ratio_mean'] = df[col] / (mean_val + 1e-6)\n",
    "            df[f'{prefix}_zscore']     = (df[col] - mean_val) / (std_val + 1e-6)\n",
    "            df[f'{prefix}_minmax']     = (df[col] - min_val) / (max_val - min_val + 1e-6)\n",
    "\n",
    "    # 7. 정규화 비율 & 밸런스\n",
    "    df['enzyme_A_per_age'] = df['enzyme_A'] / (df['age'] + 1)\n",
    "    df['enzyme_B_per_age'] = df['enzyme_B'] / (df['age'] + 1)\n",
    "    df['immune_per_age']   = df['immune_index'] / (df['age'] + 1)\n",
    "    df['lipid_per_age']    = df['lipid_index'] / (df['age'] + 1)\n",
    "\n",
    "    df['enzyme_A_per_obs'] = df['enzyme_A'] / (df['obs_days'] + 1)\n",
    "    df['immune_per_obs']   = df['immune_index'] / (df['obs_days'] + 1)\n",
    "\n",
    "    df['chem_balance'] = df['chem_01'] / (df['chem_01'] + df['chem_02'] + 1e-6)\n",
    "    df['immune_behavior_balance'] = df['immune_index'] / (df['immune_index'] + df['behavior_index'] + 1e-6)\n",
    "\n",
    "    # 8. 복합 상호작용\n",
    "    df['stage_symptom_interaction'] = df['disease_stage'] * (df['symptom_count'] + 1)\n",
    "    df['stage_immune_ratio']        = df['disease_stage'] / (df['immune_index'] + 1)\n",
    "    df['treatment_immune_ratio']    = df['treatment'] / (df['immune_index'] + 1)\n",
    "    df['treatment_symptom_ratio']   = df['treatment'] / (df['symptom_count'] + 1)\n",
    "\n",
    "    # 9. inf/NaN 처리\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    #10. 위험 요소\n",
    "    df['chem_01_range'] = pd.cut(\n",
    "    df['chem_01'], \n",
    "    bins=[-np.inf, 2.0, 4.0, np.inf], \n",
    "    labels=['Normal_Low', 'Warning_Zone', 'Danger_High']\n",
    "    )\n",
    "\n",
    "    # 2. trace_metal 구간화\n",
    "    # 90 이하는 안전, 90~130은 주의 구간, 130 이상은 위험\n",
    "    df['trace_metal_range'] = pd.cut(\n",
    "        df['trace_metal'],\n",
    "        bins=[-np.inf, 90, 130, np.inf],\n",
    "        labels=['Safe', 'Caution', 'Risk']\n",
    "    )\n",
    "\n",
    "    # 3. [고급] \"애매한 증상 + 수치 경고\" 복합 변수 만들기\n",
    "    # \"부종이 약간(S) 있으면서 & chem_01 수치가 경고 수준(2~4)인 사람\"을 찾아냅니다.\n",
    "    # 이 조합은 Target 1일 확률이 매우 높을 것입니다.\n",
    "\n",
    "    def check_ambiguous_risk(row):\n",
    "        # 증상은 애매하지만(S), 수치는 나쁜 경우\n",
    "        if (row['swelling'] == 'S') and (2.0 <= row['chem_01'] < 5.0):\n",
    "            return 'Target_1_Suspect' # 주의 단계 의심\n",
    "        elif (row['swelling'] == 'Y') or (row['chem_01'] >= 5.0):\n",
    "            return 'High_Risk'        # 위험\n",
    "        else:\n",
    "            return 'Normal'           # 정상\n",
    "\n",
    "    df['risk_segment'] = df.apply(check_ambiguous_risk, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_discrete_caution_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    주의(1) 후보 구간용 이산 피처들\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "\n",
    "    for c in [\"fluid_accum\", \"organ_enlarge\", \"vascular_marks\"]:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].replace({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "    if \"swelling_ord\" not in X.columns and \"swelling\" in X.columns:\n",
    "        X[\"swelling_ord\"] = X[\"swelling\"].map({\"N\": 0, \"S\": 1, \"Y\": 2})\n",
    "\n",
    "    for c in [\"symptom_count\", \"disease_stage\", \"behavior_index\"]:\n",
    "        if c not in X.columns:\n",
    "            X[c] = 0\n",
    "\n",
    "    # 1) 중간 병기(2~3), 중간 행동(=1)\n",
    "    X[\"stage_mid\"] = X[\"disease_stage\"].between(2, 3).astype(int)\n",
    "    X[\"beh_mid\"]   = (X[\"behavior_index\"] == 1).astype(int)\n",
    "\n",
    "    # 2) 증상 1~2개 + 부종(>=1) → 애매하게 안 좋은 구간\n",
    "    X[\"caution_symptom_zone\"] = (\n",
    "        X[\"symptom_count\"].between(1, 2) & (X[\"swelling_ord\"] >= 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 3) 병기 2~3 + 행동지수 1\n",
    "    X[\"caution_stage_beh\"] = (\n",
    "        (X[\"stage_mid\"] == 1) & (X[\"beh_mid\"] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 4) 장기비대 있지만 병기는 1, 행동은 심각하진 않은 구간\n",
    "    X[\"caution_organ_only\"] = (\n",
    "        (X[\"organ_enlarge\"] == 1)\n",
    "        & (X[\"disease_stage\"] == 1)\n",
    "        & (X[\"behavior_index\"] <= 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 5) 점수형\n",
    "    sym_score = X[\"symptom_count\"].clip(0, 3)\n",
    "    stage_score = X[\"stage_mid\"]\n",
    "    beh_score = X[\"beh_mid\"]\n",
    "\n",
    "    X[\"caution_score\"] = sym_score + stage_score + beh_score\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def add_lab_qbins(X: pd.DataFrame, n_bins: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    lab 수치형에 대해 분위 기반 qbin 추가\n",
    "    chem_01_qbin, chem_02_qbin, protein_level_qbin, trace_metal_qbin,\n",
    "    enzyme_A_qbin, enzyme_B_qbin, lipid_index_qbin, blood_cells_qbin,\n",
    "    clot_time_qbin 등\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "\n",
    "    lab_cols = [\n",
    "        \"chem_01\", \"chem_02\", \"protein_level\", \"trace_metal\",\n",
    "        \"enzyme_A\", \"enzyme_B\", \"lipid_index\", \"blood_cells\", \"clot_time\"\n",
    "    ]\n",
    "\n",
    "    for col in lab_cols:\n",
    "        if col not in X.columns:\n",
    "            continue\n",
    "        try:\n",
    "            # qbin: 0 ~ (n_bins-1)\n",
    "            X[f\"{col}_qbin\"] = pd.qcut(\n",
    "                X[col],\n",
    "                q=n_bins,\n",
    "                labels=False,\n",
    "                duplicates=\"drop\"\n",
    "            )\n",
    "        except ValueError:\n",
    "            # 유니크가 너무 적으면 스킵\n",
    "            continue\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame, is_train: bool = True):\n",
    "    \"\"\"\n",
    "    train/test 공통 전체 파이프라인:\n",
    "    - raw 정리 → boosting 피처 → caution 피처 → qbin 피처\n",
    "    - train이면 (X, y), test면 X 반환\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = prepare_raw(df)\n",
    "    df = make_boosting_features(df)\n",
    "    df = add_discrete_caution_features(df)\n",
    "    df = add_lab_qbins(df, n_bins=4)\n",
    "\n",
    "    drop_cols = [c for c in [\"index\", \"name\", \"birth_date\", \"geo_code\"] if c in df.columns]\n",
    "\n",
    "    if is_train:\n",
    "        y = df[\"target\"].values\n",
    "        X = df.drop(columns=drop_cols + [\"target\"])\n",
    "        return X, y\n",
    "    else:\n",
    "        X = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all shape: (6500, 143)\n",
      "X_all_test shape: (1405, 143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:73: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace({\"Y\": 1, \"N\": 0})\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_diff_mean']  = df[col] - mean_val\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_ratio_mean'] = df[col] / (mean_val + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_zscore']     = (df[col] - mean_val) / (std_val + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:112: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_minmax']     = (df[col] - min_val) / (max_val - min_val + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:115: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enzyme_A_per_age'] = df['enzyme_A'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enzyme_B_per_age'] = df['enzyme_B'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['immune_per_age']   = df['immune_index'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['lipid_per_age']    = df['lipid_index'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enzyme_A_per_obs'] = df['enzyme_A'] / (df['obs_days'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['immune_per_obs']   = df['immune_index'] / (df['obs_days'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['chem_balance'] = df['chem_01'] / (df['chem_01'] + df['chem_02'] + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:124: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['immune_behavior_balance'] = df['immune_index'] / (df['immune_index'] + df['behavior_index'] + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['stage_symptom_interaction'] = df['disease_stage'] * (df['symptom_count'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['stage_immune_ratio']        = df['disease_stage'] / (df['immune_index'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:129: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['treatment_immune_ratio']    = df['treatment'] / (df['immune_index'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:130: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['treatment_symptom_ratio']   = df['treatment'] / (df['symptom_count'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:73: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace({\"Y\": 1, \"N\": 0})\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:103: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_val = df.groupby(group_col)[col].transform('mean')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:104: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  std_val  = df.groupby(group_col)[col].transform('std')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  max_val  = df.groupby(group_col)[col].transform('max')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  min_val  = df.groupby(group_col)[col].transform('min')\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_diff_mean']  = df[col] - mean_val\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_ratio_mean'] = df[col] / (mean_val + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_zscore']     = (df[col] - mean_val) / (std_val + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:112: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{prefix}_minmax']     = (df[col] - min_val) / (max_val - min_val + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:115: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enzyme_A_per_age'] = df['enzyme_A'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enzyme_B_per_age'] = df['enzyme_B'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['immune_per_age']   = df['immune_index'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['lipid_per_age']    = df['lipid_index'] / (df['age'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enzyme_A_per_obs'] = df['enzyme_A'] / (df['obs_days'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['immune_per_obs']   = df['immune_index'] / (df['obs_days'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['chem_balance'] = df['chem_01'] / (df['chem_01'] + df['chem_02'] + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:124: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['immune_behavior_balance'] = df['immune_index'] / (df['immune_index'] + df['behavior_index'] + 1e-6)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['stage_symptom_interaction'] = df['disease_stage'] * (df['symptom_count'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['stage_immune_ratio']        = df['disease_stage'] / (df['immune_index'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:129: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['treatment_immune_ratio']    = df['treatment'] / (df['immune_index'] + 1)\n",
      "C:\\Users\\abc01\\AppData\\Local\\Temp\\ipykernel_25352\\3944312664.py:130: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['treatment_symptom_ratio']   = df['treatment'] / (df['symptom_count'] + 1)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 3. 데이터 로드 & 전체 피처 생성\n",
    "\n",
    "# %%\n",
    "# 파일 경로는 환경에 맞게 수정\n",
    "train_path = r\"C:\\Users\\abc01\\OneDrive\\바탕 화면\\train.csv\"\n",
    "test_path  = r\"C:\\Users\\abc01\\OneDrive\\바탕 화면\\test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "train_df = add_eda_rule_features(train_df)\n",
    "test_df  = add_eda_rule_features(test_df)\n",
    "\n",
    "X_all, y = build_features(train_df, is_train=True)\n",
    "X_all_test = build_features(test_df, is_train=False)\n",
    "\n",
    "print(\"X_all shape:\", X_all.shape)\n",
    "print(\"X_all_test shape:\", X_all_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8701ad7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM missing feats: []\n",
      "X_lgb shape: (6500, 11)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 4. 모델별 피처 서브셋 (XGB / LGBM / CAT)\n",
    "\n",
    "# %%\n",
    "# 4-1. LGBM: 미들 피처 11개\n",
    "LGBM_FEATS = [\n",
    "    'obs_days', 'chem_02', 'enzyme_B', 'blood_cells',\n",
    "    'lipid_index', 'clot_time', 'chem_01', 'trace_metal',\n",
    "    'age', 'enzyme_A', 'health_index'\n",
    "]\n",
    "\n",
    "missing_lgb = [c for c in LGBM_FEATS if c not in X_all.columns]\n",
    "print(\"LGBM missing feats:\", missing_lgb)\n",
    "\n",
    "X_lgb = X_all[LGBM_FEATS].copy()\n",
    "X_lgb_test = X_all_test[LGBM_FEATS].copy()\n",
    "print(\"X_lgb shape:\", X_lgb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277bb3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB missing feats: []\n",
      "X_xgb shape: (6500, 44)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "XGB_FEATS = [\n",
    "    'chem01_trace_combo', 'chem_01_rank', 'chem_01', 'stage_symptom_interaction',\n",
    "    'swelling_ord', 'symptom_severity', 'obs_days', 'health_per_stage', 'gender',\n",
    "    'symptom_count', 'enzyme_A_qbin', 'chem01_enzymeB_combo', 'fluid_accum',\n",
    "    'disease_velocity', 'obs_per_age', 'age', 'clot_time_qbin', 'disease_stage',\n",
    "    'clot_time', 'enzyme_B_by_gender_minmax', 'chem_01_qbin', 'trace_metal_qbin',\n",
    "    'enzyme_A_by_gender_zscore', 'health_index', 'enzyme_A_rank',\n",
    "    'caution_symptom_zone', 'enzyme_B_qbin', 'enzyme_A_by_gender_diff_mean',\n",
    "    'chem01_chem02_combo', 'enzyme_A_by_gender_ratio_mean', 'trace_metal',\n",
    "    'treatment', 'enzyme_B_by_disease_stage_zscore',\n",
    "    'enzyme_A_by_age_group_minmax', 'blood_cells', 'enzyme_B_rank', 'enzyme_B',\n",
    "    'diff_chem', 'blood_cells_by_age_group_zscore', 'enzyme_B_by_gender_diff_mean',\n",
    "    'enzyme_A', 'enzyme_A_by_disease_stage_minmax', 'chem_02_qbin', 'diff_enzyme'\n",
    "]\n",
    "\n",
    "missing_xgb = [c for c in XGB_FEATS if c not in X_all.columns]\n",
    "print(\"XGB missing feats:\", missing_xgb)\n",
    "\n",
    "X_xgb = X_all[XGB_FEATS].copy()\n",
    "X_xgb_test = X_all_test[XGB_FEATS].copy()\n",
    "print(\"X_xgb shape:\", X_xgb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ed3498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] combo_chem1_trace 생성\n",
      "[train] ratio_chem1_trace 생성\n",
      "[train] age_enzymeA 생성\n",
      "[test] combo_chem1_trace 생성\n",
      "[test] ratio_chem1_trace 생성\n",
      "[test] age_enzymeA 생성\n",
      "CAT missing feats (after fix): []\n",
      "사용 가능한 CAT 피처 수: 42\n",
      "X_cat shape: (6500, 42)\n",
      "X_cat_test shape: (1405, 42)\n"
     ]
    }
   ],
   "source": [
    "# %%  🔥 CatBoost용 피처 셋업 (새 ipynb용)\n",
    "\n",
    "CAT_FEATS = [\n",
    "    'age', 'obs_days', 'clot_time', 'disease_velocity',\n",
    "    'chem01_trace_combo', 'chem_01', 'chem01_enzymeB_combo',\n",
    "    'chem01_chem02_combo', 'combo_chem1_trace', 'obs_per_age',\n",
    "    'health_index', 'age_enzymeA', 'health_per_stage', 'lipid_per_age',\n",
    "    'enzyme_A_by_gender_zscore', 'chem_01_rank', 'chem02_trace_ratio',\n",
    "    'ratio_chem1_trace', 'enzyme_A_per_obs', 'trace_metal',\n",
    "    'immune_per_age', 'enzyme_ratio', 'immune_per_obs', 'sum_chem',\n",
    "    'chem_balance', 'enzyme_B_by_disease_stage_minmax',\n",
    "    'protein_level_by_disease_stage_minmax', 'enzyme_A_per_age',\n",
    "    'treatment_immune_ratio', 'enzyme_B_by_disease_stage_diff_mean',\n",
    "    'diff_chem', 'enzyme_A_by_disease_stage_diff_mean',\n",
    "    'lipid_blood_ratio', 'enzyme_B_per_age', 'stage_symptom_interaction',\n",
    "    'lipid_index', 'blood_cells', 'chem_02', 'disease_stage',\n",
    "    'trace_metal_rank', 'enzyme_B', 'enzyme_A'\n",
    "]\n",
    "\n",
    "# 1) X_all / X_all_test에 없는 파생 피처 3개 직접 생성\n",
    "for df_name, df in [(\"train\", X_all), (\"test\", X_all_test)]:\n",
    "    cols = set(df.columns)\n",
    "\n",
    "    # combo_chem1_trace = chem_01 * trace_metal\n",
    "    if \"combo_chem1_trace\" not in cols and {\"chem_01\", \"trace_metal\"} <= cols:\n",
    "        df[\"combo_chem1_trace\"] = df[\"chem_01\"] * df[\"trace_metal\"]\n",
    "        print(f\"[{df_name}] combo_chem1_trace 생성\")\n",
    "\n",
    "    # ratio_chem1_trace = chem_01 / (trace_metal + 1e-3)\n",
    "    if \"ratio_chem1_trace\" not in cols and {\"chem_01\", \"trace_metal\"} <= cols:\n",
    "        df[\"ratio_chem1_trace\"] = df[\"chem_01\"] / (df[\"trace_metal\"] + 1e-3)\n",
    "        print(f\"[{df_name}] ratio_chem1_trace 생성\")\n",
    "\n",
    "    # age_enzymeA = age * enzyme_A\n",
    "    cols = set(df.columns)  # 위에서 추가됐을 수 있으니 갱신\n",
    "    if \"age_enzymeA\" not in cols and {\"age\", \"enzyme_A\"} <= cols:\n",
    "        df[\"age_enzymeA\"] = df[\"age\"] * df[\"enzyme_A\"]\n",
    "        print(f\"[{df_name}] age_enzymeA 생성\")\n",
    "\n",
    "# 2) 여전히 없는 피처 있는지 체크\n",
    "missing_cat = [c for c in CAT_FEATS if c not in X_all.columns]\n",
    "print(\"CAT missing feats (after fix):\", missing_cat)\n",
    "\n",
    "# 3) 실제 존재하는 피처만 사용 (안전장치)\n",
    "use_cat_feats = [c for c in CAT_FEATS if c in X_all.columns]\n",
    "print(\"사용 가능한 CAT 피처 수:\", len(use_cat_feats))\n",
    "\n",
    "X_cat = X_all[use_cat_feats].copy()\n",
    "X_cat_test = X_all_test[use_cat_feats].copy()\n",
    "print(\"X_cat shape:\", X_cat.shape)\n",
    "print(\"X_cat_test shape:\", X_cat_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb3edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 5. 모델 정의 (best params 적용)\n",
    "\n",
    "# %%\n",
    "# 5-1. XGB\n",
    "best_params_xgb = {\n",
    "    \"max_depth\": 7,\n",
    "    \"min_child_weight\": 9,\n",
    "    \"gamma\": 0.584258780685998,\n",
    "    \"learning_rate\": 0.026313469973063427,\n",
    "    \"n_estimators\": 400,\n",
    "    \"subsample\": 0.7263129521191727,\n",
    "    \"colsample_bytree\": 0.6546519462568459,\n",
    "    \"reg_alpha\": 0.7771992619497006,\n",
    "    \"reg_lambda\": 0.774928257935245,\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "model_xgb = XGBClassifier(**best_params_xgb)\n",
    "\n",
    "\n",
    "# 5-2. LGBM (mid 11 feats)\n",
    "best_params_lgb = {\n",
    "    \"num_leaves\": 22,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_samples\": 84,\n",
    "    \"learning_rate\": 0.02556093432307773,\n",
    "    \"n_estimators\": 347,\n",
    "    \"subsample\": 0.9121058633121536,\n",
    "    \"colsample_bytree\": 0.5175827719114479,\n",
    "    \"reg_alpha\": 1.5903402527689057,\n",
    "    \"reg_lambda\": 1.1779816064263182,\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "model_lgb = LGBMClassifier(**best_params_lgb)\n",
    "\n",
    "\n",
    "# 5-3. CatBoost (네가 튜닝한 결과로 나중에 업데이트)\n",
    "best_params_cat = {\n",
    "    \"iterations\": 1439,   # 자리표시자: 너가 찾은 best로 교체\n",
    "    \"depth\": 4,\n",
    "    \"learning_rate\": 0.05302188493570401,\n",
    "    \"l2_leaf_reg\": 1.09403474693172,\n",
    "    \"bagging_temperature\": 0.48512743870498,\n",
    "    \"random_strength\": 1.5516425976084334,\n",
    "    \"border_count\": 89,\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"eval_metric\": \"MultiClass\",\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"thread_count\": -1,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "model_cat = CatBoostClassifier(**best_params_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf11d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b56633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] Fold 1/10 mAP = 0.691488\n",
      "[XGB] Fold 2/10 mAP = 0.682504\n",
      "[XGB] Fold 3/10 mAP = 0.663161\n",
      "[XGB] Fold 4/10 mAP = 0.713433\n",
      "[XGB] Fold 5/10 mAP = 0.759052\n",
      "[XGB] Fold 6/10 mAP = 0.729224\n",
      "[XGB] Fold 7/10 mAP = 0.663906\n",
      "[XGB] Fold 8/10 mAP = 0.692875\n",
      "[XGB] Fold 9/10 mAP = 0.766981\n",
      "[XGB] Fold 10/10 mAP = 0.659785\n",
      "[XGB] OOF mean mAP = 0.702241\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 1/10 mAP = 0.695395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2588\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 2/10 mAP = 0.675049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 3/10 mAP = 0.670266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 4/10 mAP = 0.697007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 5/10 mAP = 0.727913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 6/10 mAP = 0.703766\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 7/10 mAP = 0.659506\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 8/10 mAP = 0.728803\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 9/10 mAP = 0.764266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2584\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 10/10 mAP = 0.670588\n",
      "[LGBM] OOF mean mAP = 0.699256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CAT] Fold 1/10 mAP = 0.681933\n",
      "[CAT] Fold 2/10 mAP = 0.660296\n",
      "[CAT] Fold 3/10 mAP = 0.664877\n",
      "[CAT] Fold 4/10 mAP = 0.716398\n",
      "[CAT] Fold 5/10 mAP = 0.743040\n",
      "[CAT] Fold 6/10 mAP = 0.715236\n",
      "[CAT] Fold 7/10 mAP = 0.651158\n",
      "[CAT] Fold 8/10 mAP = 0.684367\n",
      "[CAT] Fold 9/10 mAP = 0.729313\n",
      "[CAT] Fold 10/10 mAP = 0.667796\n",
      "[CAT] OOF mean mAP = 0.691441\n",
      "oof_xgb shape: (6500, 3)\n",
      "oof_lgb shape: (6500, 3)\n",
      "oof_cat shape: (6500, 3)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 6. 3개 모델 OOF 확률 생성\n",
    "\n",
    "# %%\n",
    "oof_xgb, _ = get_oof_proba(model_xgb, X_xgb, y, name=\"XGB\")\n",
    "oof_lgb, _ = get_oof_proba(model_lgb, X_lgb, y, name=\"LGBM\")\n",
    "oof_cat, _ = get_oof_proba(model_cat, X_cat, y, name=\"CAT\")\n",
    "\n",
    "print(\"oof_xgb shape:\", oof_xgb.shape)\n",
    "print(\"oof_lgb shape:\", oof_lgb.shape)\n",
    "print(\"oof_cat shape:\", oof_cat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c301c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 앙상블 weight search 결과 ===\n",
      "Best ensemble mAP: 0.6932049158288831\n",
      "Best weights (XGB, LGBM, CAT): (0.425531914893617, 0.3191489361702127, 0.2553191489361702)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 7. 앙상블 가중치 grid search (mAP 최대화)\n",
    "\n",
    "# %%\n",
    "from itertools import product\n",
    "\n",
    "def search_ensemble_weights(\n",
    "    y_true,\n",
    "    oof_xgb,\n",
    "    oof_lgb,\n",
    "    oof_cat,\n",
    "    step=0.1\n",
    "):\n",
    "    best_score = -1.0\n",
    "    best_w = (1/3, 1/3, 1/3)\n",
    "\n",
    "    ws = [round(x, 2) for x in np.arange(0.0, 1.0 + 1e-9, step)]\n",
    "\n",
    "    for w1, w2, w3 in product(ws, ws, ws):\n",
    "        if w1 + w2 + w3 == 0:\n",
    "            continue\n",
    "        s = w1 + w2 + w3\n",
    "        w1_n, w2_n, w3_n = w1/s, w2/s, w3/s\n",
    "\n",
    "        proba_ens = (\n",
    "            w1_n * oof_xgb +\n",
    "            w2_n * oof_lgb +\n",
    "            w3_n * oof_cat\n",
    "        )\n",
    "\n",
    "        score = map_macro(y_true, proba_ens)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_w = (w1_n, w2_n, w3_n)\n",
    "\n",
    "    return best_w, best_score\n",
    "\n",
    "\n",
    "best_w, best_score = search_ensemble_weights(\n",
    "    y,\n",
    "    oof_xgb,\n",
    "    oof_lgb,\n",
    "    oof_cat,\n",
    "    step=0.05   # 0.05로 더 세밀하게 가도 됨(시간 조금 증가)\n",
    ")\n",
    "\n",
    "print(\"\\n=== 앙상블 weight search 결과 ===\")\n",
    "print(\"Best ensemble mAP:\", best_score)\n",
    "print(\"Best weights (XGB, LGBM, CAT):\", best_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9063b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_xgb: (6500, 44) X_xgb_test: (1405, 44)\n",
      "X_lgb: (6500, 11) X_lgb_test: (1405, 11)\n",
      "X_cat: (6500, 42) X_cat_test: (1405, 42)\n",
      "\n",
      "[Train] XGB full fit...\n",
      "[Train] LGBM full fit...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.359022\n",
      "[LightGBM] [Info] Start training from score -1.086076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[Train] CAT full fit...\n",
      "proba_xgb_test: (1405, 3)\n",
      "proba_lgb_test: (1405, 3)\n",
      "proba_cat_test: (1405, 3)\n",
      "✅ 확률 제출 파일 저장 완료: C:\\Users\\abc01\\OneDrive\\바탕 화면\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 0. 데이터 / 피처 준비 (이미 있다고 가정)\n",
    "#    - train_df, test_df\n",
    "#    - y\n",
    "#    - X_xgb, X_xgb_test\n",
    "#    - X_lgb, X_lgb_test\n",
    "#    - X_cat, X_cat_test\n",
    "# ─────────────────────────────\n",
    "# 위 것들은 너가 이미 전처리 + 피처셀렉까지 끝낸 상태에서 쓰던 것 그대로 사용하면 됨\n",
    "\n",
    "print(\"X_xgb:\", X_xgb.shape, \"X_xgb_test:\", X_xgb_test.shape)\n",
    "print(\"X_lgb:\", X_lgb.shape, \"X_lgb_test:\", X_lgb_test.shape)\n",
    "print(\"X_cat:\", X_cat.shape, \"X_cat_test:\", X_cat_test.shape)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 1. 각 모델 최종 하이퍼파라미터 세팅\n",
    "# ─────────────────────────────\n",
    "\n",
    "# 1) XGBoost (final_features 기준 Optuna best)\n",
    "xgb_final = XGBClassifier(\n",
    "    max_depth=7,\n",
    "    min_child_weight=9,\n",
    "    gamma=0.584258780685998,\n",
    "    learning_rate=0.026313469973063427,\n",
    "    n_estimators=400,\n",
    "    subsample=0.7263129521191727,\n",
    "    colsample_bytree=0.6546519462568459,\n",
    "    reg_alpha=0.7771992619497006,\n",
    "    reg_lambda=0.774928257935245,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=3,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) LightGBM (미들 피처 11개 Optuna best)\n",
    "lgb_final = LGBMClassifier(\n",
    "    n_estimators=347,\n",
    "    num_leaves=22,\n",
    "    max_depth=9,\n",
    "    min_child_samples=84,\n",
    "    learning_rate=0.02556093432307773,\n",
    "    subsample=0.9121058633121536,\n",
    "    colsample_bytree=0.5175827719114479,\n",
    "    reg_alpha=1.5903402527689057,\n",
    "    reg_lambda=1.1779816064263182,\n",
    "    objective=\"multiclass\",\n",
    "    num_class=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) CatBoost (CAT_FEATS 기준 Optuna best)\n",
    "cat_final = CatBoostClassifier(\n",
    "    iterations=1325,\n",
    "    depth=3,\n",
    "    learning_rate=0.047163049101853795,\n",
    "    l2_leaf_reg=0.5524276151256475,\n",
    "    bagging_temperature=1.3500372949148198,\n",
    "    random_strength=1.474723113115535,\n",
    "    border_count=74,\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 2. train 전체로 각 모델 학습\n",
    "# ─────────────────────────────\n",
    "\n",
    "print(\"\\n[Train] XGB full fit...\")\n",
    "xgb_final.fit(X_xgb, y)\n",
    "\n",
    "print(\"[Train] LGBM full fit...\")\n",
    "lgb_final.fit(X_lgb, y)\n",
    "\n",
    "print(\"[Train] CAT full fit...\")\n",
    "cat_final.fit(X_cat, y)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 3. test 확률 예측\n",
    "# ─────────────────────────────\n",
    "\n",
    "proba_xgb_test = xgb_final.predict_proba(X_xgb_test)\n",
    "proba_lgb_test = lgb_final.predict_proba(X_lgb_test)\n",
    "proba_cat_test = cat_final.predict_proba(X_cat_test)\n",
    "\n",
    "print(\"proba_xgb_test:\", proba_xgb_test.shape)\n",
    "print(\"proba_lgb_test:\", proba_lgb_test.shape)\n",
    "print(\"proba_cat_test:\", proba_cat_test.shape)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 4. 가중 앙상블 (너가 찾은 best weights 사용)\n",
    "# ─────────────────────────────\n",
    "\n",
    "w_xgb = 0.425531914893617\n",
    "w_lgb = 0.3191489361702127\n",
    "w_cat = 0.2553191489361702\n",
    "\n",
    "proba_test_ens = (\n",
    "    w_xgb * proba_xgb_test +\n",
    "    w_lgb * proba_lgb_test +\n",
    "    w_cat * proba_cat_test\n",
    ")\n",
    "\n",
    "# 최종 predicted class (argmax)\n",
    "pred_test = np.argmax(proba_test_ens, axis=1)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 5. CSV 저장 (✔ proba만, 바탕화면 submission.csv)\n",
    "# ─────────────────────────────\n",
    "\n",
    "# proba_test_ens: (n_samples, 3)  ← 가중 앙상블 확률\n",
    "proba_df = pd.DataFrame(\n",
    "    proba_test_ens,\n",
    "    columns=[\"prob_class_0\", \"prob_class_1\", \"prob_class_2\"]\n",
    ")\n",
    "\n",
    "# index 붙이기\n",
    "proba_df.insert(0, \"index\", test_df[\"index\"].values)\n",
    "\n",
    "output_path = r\"C:\\Users\\abc01\\OneDrive\\바탕 화면\\submission.csv\"\n",
    "proba_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ 확률 제출 파일 저장 완료: {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0983c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== XGB OOF (no weight) =====\n",
      "[XGB] Fold 1/10 mAP = 0.691488\n",
      "[XGB] Fold 2/10 mAP = 0.682504\n",
      "[XGB] Fold 3/10 mAP = 0.663161\n",
      "[XGB] Fold 4/10 mAP = 0.713433\n",
      "[XGB] Fold 5/10 mAP = 0.759052\n",
      "[XGB] Fold 6/10 mAP = 0.729224\n",
      "[XGB] Fold 7/10 mAP = 0.663906\n",
      "[XGB] Fold 8/10 mAP = 0.692875\n",
      "[XGB] Fold 9/10 mAP = 0.766981\n",
      "[XGB] Fold 10/10 mAP = 0.659785\n",
      "[XGB] OOF mean mAP = 0.702241\n",
      "\n",
      "===== LGBM OOF (no weight) =====\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 1/10 mAP = 0.695395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2588\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 2/10 mAP = 0.675049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 3/10 mAP = 0.670266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.356077\n",
      "[LightGBM] [Info] Start training from score -1.086380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 4/10 mAP = 0.697007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 5/10 mAP = 0.727913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 6/10 mAP = 0.703766\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 7/10 mAP = 0.659506\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LGBM] Fold 8/10 mAP = 0.728803\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2586\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 9/10 mAP = 0.764266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2584\n",
      "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.360991\n",
      "[LightGBM] [Info] Start training from score -1.085873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc01\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 10/10 mAP = 0.670588\n",
      "[LGBM] OOF mean mAP = 0.699256\n",
      "\n",
      "===== CAT OOF (no weight) =====\n",
      "[CAT] Fold 1/10 mAP = 0.681933\n",
      "[CAT] Fold 2/10 mAP = 0.660296\n",
      "[CAT] Fold 3/10 mAP = 0.664877\n",
      "[CAT] Fold 4/10 mAP = 0.716398\n",
      "[CAT] Fold 5/10 mAP = 0.743040\n",
      "[CAT] Fold 6/10 mAP = 0.715236\n",
      "[CAT] Fold 7/10 mAP = 0.651158\n",
      "[CAT] Fold 8/10 mAP = 0.684367\n",
      "[CAT] Fold 9/10 mAP = 0.729313\n",
      "[CAT] Fold 10/10 mAP = 0.667796\n",
      "[CAT] OOF mean mAP = 0.691441\n",
      "oof_xgb: (6500, 3)\n",
      "oof_lgb: (6500, 3)\n",
      "oof_cat: (6500, 3)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 1. 3개 베이스 모델 OOF 확률 (가중치 X)\n",
    "\n",
    "# %%\n",
    "print(\"===== XGB OOF (no weight) =====\")\n",
    "oof_xgb, _ = get_oof_proba(\n",
    "    model_xgb,\n",
    "    X_xgb, y,\n",
    "    n_splits=10,\n",
    "    random_state=42,\n",
    "    name=\"XGB\"\n",
    ")\n",
    "\n",
    "print(\"\\n===== LGBM OOF (no weight) =====\")\n",
    "oof_lgb, _ = get_oof_proba(\n",
    "    model_lgb,\n",
    "    X_lgb, y,\n",
    "    n_splits=10,\n",
    "    random_state=42,\n",
    "    name=\"LGBM\"\n",
    ")\n",
    "\n",
    "print(\"\\n===== CAT OOF (no weight) =====\")\n",
    "oof_cat, _ = get_oof_proba(\n",
    "    model_cat,\n",
    "    X_cat, y,\n",
    "    n_splits=10,\n",
    "    random_state=42,\n",
    "    name=\"CAT\"\n",
    ")\n",
    "\n",
    "print(\"oof_xgb:\", oof_xgb.shape)\n",
    "print(\"oof_lgb:\", oof_lgb.shape)\n",
    "print(\"oof_cat:\", oof_cat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ddfc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_train shape: (6500, 9)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2587\n",
      "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.465705\n",
      "[LightGBM] [Info] Start training from score -3.359022\n",
      "[LightGBM] [Info] Start training from score -1.086076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Z_test shape: (1405, 9)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 2. 메타 입력 피처(Z_train, Z_test) 생성\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "# 2-1) train용 meta-feature (OOF 기반)\n",
    "Z_train = np.hstack([oof_xgb, oof_lgb, oof_cat])\n",
    "print(\"Z_train shape:\", Z_train.shape)  # (n_samples, 9 예상)\n",
    "\n",
    "# 2-2) base 모델을 전체 train으로 다시 학습해서 test 확률 생성\n",
    "final_xgb = clone(model_xgb)\n",
    "final_xgb.fit(X_xgb, y)\n",
    "proba_xgb_test = final_xgb.predict_proba(X_xgb_test)\n",
    "\n",
    "final_lgb = clone(model_lgb)\n",
    "final_lgb.fit(X_lgb, y)\n",
    "proba_lgb_test = final_lgb.predict_proba(X_lgb_test)\n",
    "\n",
    "final_cat = clone(model_cat)\n",
    "final_cat.fit(X_cat, y)\n",
    "proba_cat_test = final_cat.predict_proba(X_cat_test)\n",
    "\n",
    "Z_test = np.hstack([proba_xgb_test, proba_lgb_test, proba_cat_test])\n",
    "print(\"Z_test shape:\", Z_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc1af10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def search_best_pair_weight(oof_a, oof_b, y, name_a=\"A\", name_b=\"B\", n_grid=101):\n",
    "    \"\"\"\n",
    "    oof_a, oof_b : (n_samples, n_classes) OOF 확률\n",
    "    y            : 정답 레이블\n",
    "    n_grid       : 0~1 사이를 몇 개로 나눌지 (101 -> 0.00,0.01,...,1.00)\n",
    "    \"\"\"\n",
    "    best_w = None\n",
    "    best_score = -1.0\n",
    "    history = []\n",
    "\n",
    "    ws = np.linspace(0, 1, n_grid)\n",
    "    for w in ws:\n",
    "        proba = w * oof_a + (1 - w) * oof_b\n",
    "        score = average_precision_score(y, proba, average=\"macro\")\n",
    "        history.append((w, score))\n",
    "        # 필요하면 여기서 print(f\"{name_a}={w:.3f}, {name_b}={1-w:.3f}, mAP={score:.6f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_w = w\n",
    "\n",
    "    print(f\"\\n🔎 [{name_a} + {name_b}] best mAP = {best_score:.6f}, \"\n",
    "          f\"weights=({name_a}={best_w:.3f}, {name_b}={1-best_w:.3f})\")\n",
    "\n",
    "    return best_w, best_score, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9d2a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 [XGB + LGBM] best mAP = 0.691253, weights=(XGB=0.500, LGBM=0.500)\n",
      "\n",
      "🔎 [XGB + CAT] best mAP = 0.691218, weights=(XGB=0.670, CAT=0.330)\n",
      "\n",
      "🔎 [LGBM + CAT] best mAP = 0.690198, weights=(LGBM=0.510, CAT=0.490)\n",
      "\n",
      "===== 2-모델 앙상블 비교 =====\n",
      "XGB + LGBM : 0.691253 (w=0.500/0.500)\n",
      "XGB + CAT  : 0.691218 (w=0.670/0.330)\n",
      "LGBM + CAT : 0.690198 (w=0.510/0.490)\n"
     ]
    }
   ],
   "source": [
    "# 이미 있는 OOF:\n",
    "# oof_xgb, oof_lgb, oof_cat\n",
    "# y\n",
    "\n",
    "w_xl, sc_xl, hist_xl = search_best_pair_weight(oof_xgb, oof_lgb, y, \"XGB\", \"LGBM\")\n",
    "w_xc, sc_xc, hist_xc = search_best_pair_weight(oof_xgb, oof_cat, y, \"XGB\", \"CAT\")\n",
    "w_lc, sc_lc, hist_lc = search_best_pair_weight(oof_lgb, oof_cat, y, \"LGBM\", \"CAT\")\n",
    "\n",
    "print(\"\\n===== 2-모델 앙상블 비교 =====\")\n",
    "print(f\"XGB + LGBM : {sc_xl:.6f} (w={w_xl:.3f}/{1-w_xl:.3f})\")\n",
    "print(f\"XGB + CAT  : {sc_xc:.6f} (w={w_xc:.3f}/{1-w_xc:.3f})\")\n",
    "print(f\"LGBM + CAT : {sc_lc:.6f} (w={w_lc:.3f}/{1-w_lc:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19941828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 최종 선택된 조합: XL, mAP=0.691253, w=0.500/0.500\n",
      "proba_test_ens_2 shape: (1405, 3)\n",
      "✅ 2-모델 앙상블 proba 저장 완료: C:\\Users\\abc01\\OneDrive\\바탕 화면\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 이미 있는 test proba\n",
    "# proba_xgb_test, proba_lgb_test, proba_cat_test\n",
    "# test_df (index 포함)\n",
    "\n",
    "# 1) 제일 좋은 조합 자동 선택\n",
    "scores_pairs = {\n",
    "    \"XL\": (sc_xl, w_xl),  # XGB + LGBM\n",
    "    \"XC\": (sc_xc, w_xc),  # XGB + CAT\n",
    "    \"LC\": (sc_lc, w_lc),  # LGBM + CAT\n",
    "}\n",
    "\n",
    "best_key = max(scores_pairs.keys(), key=lambda k: scores_pairs[k][0])\n",
    "best_score, best_w = scores_pairs[best_key]\n",
    "print(f\"\\n🔥 최종 선택된 조합: {best_key}, mAP={best_score:.6f}, w={best_w:.3f}/{1-best_w:.3f}\")\n",
    "\n",
    "# 2) test 확률 앙상블\n",
    "if best_key == \"XL\":\n",
    "    proba_test_ens_2 = best_w * proba_xgb_test + (1 - best_w) * proba_lgb_test\n",
    "elif best_key == \"XC\":\n",
    "    proba_test_ens_2 = best_w * proba_xgb_test + (1 - best_w) * proba_cat_test\n",
    "elif best_key == \"LC\":\n",
    "    proba_test_ens_2 = best_w * proba_lgb_test + (1 - best_w) * proba_cat_test\n",
    "else:\n",
    "    raise ValueError(\"알 수 없는 조합 키:\", best_key)\n",
    "\n",
    "print(\"proba_test_ens_2 shape:\", proba_test_ens_2.shape)\n",
    "\n",
    "# 3) proba 제출 파일 생성 (index + 확률 3개)\n",
    "proba_df_2 = pd.DataFrame(\n",
    "    proba_test_ens_2,\n",
    "    columns=[\"prob_class_0\", \"prob_class_1\", \"prob_class_2\"]\n",
    ")\n",
    "proba_df_2.insert(0, \"index\", test_df[\"index\"].values)\n",
    "\n",
    "output_path = r\"C:\\Users\\abc01\\OneDrive\\바탕 화면\\submission.csv\"\n",
    "proba_df_2.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ 2-모델 앙상블 proba 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce11bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train: (6500, 24) test: (1405, 23)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     53\u001b[39m test_eda  = add_eda_rule_features(test_raw)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 2) 거대 피처 (네가 쓰던 preprocess_all 그대로 사용)\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m#    preprocess_all 은 (X_big, y, lab_config) 반환하는 버전이라고 가정\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m X_big, y, lab_config = \u001b[43mpreprocess_all\u001b[49m(train_eda, is_train=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     58\u001b[39m X_big_test           = preprocess_all(test_eda,  is_train=\u001b[38;5;28;01mFalse\u001b[39;00m, lab_config=lab_config)\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mX_big :\u001b[39m\u001b[33m\"\u001b[39m, X_big.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocess_all' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
